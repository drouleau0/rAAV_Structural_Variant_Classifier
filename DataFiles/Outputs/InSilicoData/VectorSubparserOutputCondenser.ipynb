{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c4c386-95c8-4028-9a0a-244fae0b22b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# This code goes through all subparse output files (vector only) in a directory and condenses the summary tables into one table\n",
    "# Only args required are the input and output dir:\n",
    "    # input_dir: top level directory containing all subparse output; same as the output dir given to the subparser script\n",
    "    # directory to put the output file (csv) of this code into\n",
    "input_dir = 'subparsing/'\n",
    "output_dir = 'condensed_subparsed/'\n",
    "\n",
    "# you can probably leave the rest of this code as-is\n",
    "# get all subparser output files in directory (recursive)\n",
    "subparser_output_directory = input_dir\n",
    "list_of_subparser_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(subparser_output_directory):\n",
    "    for filename in filenames:\n",
    "        if 'subparsed.tsv' in filename:\n",
    "            list_of_subparser_files.append(os.path.join(dirpath, filename))\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# get top data table from each subparser file\n",
    "subparser_file_matrices = []\n",
    "for subparser_file in list_of_subparser_files:\n",
    "    with open(subparser_file, 'r') as f:\n",
    "        subparser_matrix = []\n",
    "        for line in f:\n",
    "            if 'Bin' in line:  # skip header row\n",
    "                continue\n",
    "            elif 'Totals' in line:  # stop add Totals row, don't add it\n",
    "                subparser_matrix.append(line.split() + ['N/A'])\n",
    "                break\n",
    "            else:\n",
    "                line = line.split()\n",
    "                line[1] = float(line[1])\n",
    "                subparser_matrix.append(line)\n",
    "        for line in subparser_matrix:\n",
    "            line[2] = round(float(line[2]) * 100, 2)\n",
    "            line.insert(0, os.path.basename(subparser_file))  # add source file as column to matrix\n",
    "    subparser_file_matrices.append(subparser_matrix)\n",
    "\n",
    "# convert matrices list into a single dataframe\n",
    "subparser_dataframe = pd.DataFrame(columns=['File', 'Category', 'Sequences', 'Percent_of_File', 'Tile_Patterns', 'Percent_Full'])\n",
    "for matrix in subparser_file_matrices:\n",
    "    for line in matrix:\n",
    "        subparser_dataframe.loc[len(subparser_dataframe)] = line\n",
    "\n",
    "subparser_dataframe['sort_col'] = subparser_dataframe['Sequences'].apply(lambda x: x if isinstance(x, float) else -1000)\n",
    "subparser_dataframe.sort_values(by=['File', 'sort_col'], ascending=[True, False], inplace=True)\n",
    "subparser_dataframe.drop(columns='sort_col', axis=1, inplace = True)\n",
    "\n",
    "\n",
    "output_filename = 'all.subparsed.csv'\n",
    "# while True:\n",
    "#     head, tail = os.path.split(input_dir)\n",
    "#     input_dir = head\n",
    "#     if '-' in tail:\n",
    "#         output_filename = f'{tail}_{output_filename}'\n",
    "#         break\n",
    "#     if not head:\n",
    "#         break\n",
    "        \n",
    "subparser_dataframe.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cf1a4b-a2b7-4a5d-8d80-5ae5d73cf5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # ad hoc script condenses data for paper\n",
    "\n",
    "input_file = 'condensed_subparsed/all.subparsed.csv'\n",
    "output_file = 'condensed_subparsed/all.subparsed_condensed.csv'\n",
    "\n",
    "empty_row = {'Subclassification': '', 'Mutation_Rate': 0, 'Matches': 0, 'Misses': 0, 'Proportion_Matches': 0}\n",
    "row = empty_row.copy()\n",
    "df = pd.DataFrame(columns = ['Subclassification', 'Mutation_Rate', 'Matches', 'Misses', 'Proportion_Matches'])\n",
    "\n",
    "with open(input_file, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.split(',')\n",
    "        if line[0] == 'File':  # skip header\n",
    "            continue\n",
    "        elif not row['Subclassification']:\n",
    "            row['Subclassification'] = line[0].split('_m')[0]\n",
    "            row['Mutation_Rate'] = float(line[0].split('.')[0].split('_m_')[1]) / 100\n",
    "        elif line[1] == 'Totals':\n",
    "            row['Proportion_Matches'] = row['Matches'] / (row['Matches'] + row['Misses'])\n",
    "            df.loc[len(df)] = row\n",
    "            row = empty_row.copy()\n",
    "            continue\n",
    "        if row['Matches'] and line[1] == line[0].split('_m_')[0]:\n",
    "            raise ValueError(f'\\nmatch should not be set twice; line:{line}\\nrow:{row}')\n",
    "        elif not row['Matches'] and line[1] in line[0]:\n",
    "            row['Matches'] = float(line[2])\n",
    "        else:\n",
    "            row['Misses'] += float(line[2])\n",
    "\n",
    "df.to_csv(output_file, index=False)\n",
    "print('done successfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
